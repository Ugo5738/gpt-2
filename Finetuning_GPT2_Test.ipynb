{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning GPT2 Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14ppCt4xFJJ7hAtOrnorv-pdMc7ZBpal2",
      "authorship_tag": "ABX9TyP9t1+sQLza+BIpZBvjbjaY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ugo5738/gpt-2/blob/master/Finetuning_GPT2_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o32Dsy9Z4JOS"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mK0w_xQNimT",
        "outputId": "3e674d18-0166-4502-b940-48fb413e3e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "%cd drive\n",
        "%cd My\\ Drive\n",
        "%mkdir storyteller\n",
        "%cd /content/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "mkdir: cannot create directory ‘storyteller’: File exists\n",
            "/content\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrI3Jd-a4eUj"
      },
      "source": [
        "Clone mohamad-ali-nasser github repository which is 9 commits ahead of nshepperd where you have train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn3K3YE24pVd"
      },
      "source": [
        "Download the size of pretrained model you want to use into gpt-2 folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZPfv5a_8uwZ",
        "outputId": "98894362-53c0-49e4-81d9-ecadb0829d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Ugo5738/gpt-2.git\n",
        "\n",
        "%cd gpt-2\n",
        "!python download_model.py 345M\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 398 (delta 0), reused 0 (delta 0), pack-reused 395\u001b[K\n",
            "Receiving objects: 100% (398/398), 4.43 MiB | 23.89 MiB/s, done.\n",
            "Resolving deltas: 100% (216/216), done.\n",
            "/content/gpt-2\n",
            "Fetching checkpoint: 1.00kit [00:00, 1.28Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 44.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.26Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:17, 82.8Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 9.07Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 49.9Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 47.8Mit/s]                                                       \n",
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 17.6MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=721cac02c9b998af5c90e2cade81c06ec898195512da97fc08b301016e4146ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533197 sha256=ad04d7c5db48b1f07beb2ffd80b1e34c0f242e7bc9b6170947c1c129df85d1a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm, toposort\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.3.1 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rekcUwEH33Rb",
        "outputId": "15394640-0b1c-4e58-ac5c-6b2265bf1fc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.15.0\n",
        "!pip3 install 'tensorflow-estimator<1.15.0rc0,>=1.14.0rc0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 43kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.33.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.10.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 59.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=487c4f00664d85d833a6921662401d01591fa3286fbf2fb857d0062676d65d3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, keras-applications, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 11.0MB/s \n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_eppsZz4PUX"
      },
      "source": [
        "Go into Drive and create a checkpoint folder (storyteller)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACLF2Ll3dBX"
      },
      "source": [
        "# In Case I have saved checkpoints\n",
        "!cp -r /content/drive/My\\ Drive/storyteller/gpt-2/checkpoint/run1/* /content/gpt-2/models/1558M\n",
        "\n",
        "# check if this code is correct\n",
        "\n",
        "# In Case I have saved checkpoints\n",
        "!cp -r /content/drive/My\\ Drive/checkpoint/ /content/gpt-2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PY5YwWU7e_1",
        "outputId": "57b6a7b7-3c84-4964-d617-b9c028a5c4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add all text into one file\n",
        "\n",
        "%cd /content/gpt-2\n",
        "%cd src\n",
        "%mkdir corpus\n",
        "%cd corpus/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n",
            "/content/gpt-2/src\n",
            "/content/gpt-2/src/corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6h_MG2p5SsT"
      },
      "source": [
        "Creating Text content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urnCkMDqG55z"
      },
      "source": [
        "# Function to convert pdf to txt\n",
        "\n",
        "!pip3 install PyPDF2\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def pdf_to_converter(file_location):\n",
        "    pdf_file_obj = open(f\"{file_location}.pdf\",'rb')\n",
        "    pdf_reader = PyPDF2.PdfFileReader(pdf_file_obj)\n",
        "    x=pdf_reader.numPages\n",
        "    page_obj = pdf_reader.getPage(x-1)\n",
        "    text = page_obj.extractText()\n",
        "\n",
        "    file1 = open(rf\"{file_location}.txt\",\"a\")\n",
        "    file1.writelines(text)\n",
        "    file1.close()\n",
        "\n",
        "pdf_to_converter('/content/drive/My Drive/Escape-from-Samsara')\n",
        "pdf_to_converter(\"/content/drive/My Drive/Alice's_Adventures_in_Wonderland_by_Lewis_Carroll\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtiiruA42sfL"
      },
      "source": [
        "Get text from google drive if it exists, otherwise get them from the provided url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfklOyF036L1"
      },
      "source": [
        "import requests\n",
        "import os \n",
        "\n",
        "file_names = [\"internet_archive_scifi_v3.txt\", \"Alice's_Adventures_in_Wonderland_by_Lewis_Carroll.txt\", \"Escape-from-Samsara.txt\", \"Heavenly-Chat.txt\", \"Heretic-The-Life-of-a-Witch-Hunter.txt\", \"The-24-Elders-The-Last-World.txt\", \"Truth-in-Time.txt\"]\n",
        "\n",
        "for file in file_names:\n",
        "    with open(file, 'w') as f:\n",
        "        f.write(data.text)\n",
        "    f.close()\n",
        "\n",
        "\"\"\"    \n",
        "    if not os.path.isfile(file):\n",
        "    # if not \"/content/drive/My Drive/Stories for GPT2\":\n",
        "        url = \"http://www.gutenberg.org/files/1661/1661-0.txt\"\n",
        "        data = requests.get(url)\n",
        "        with open(file, 'w') as f:\n",
        "            f.write(data.text)\n",
        "        f.close()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Qb4Nbl5MGD"
      },
      "source": [
        "Create a corpus folder and move your training text into it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhtBEHlR22HR"
      },
      "source": [
        "Use the code below to merge multiple text files that have been downloaded into one. But ignore if the file is just one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik_5F0fwx7XC",
        "outputId": "f5dc3ea6-2208-4a2f-a15d-8d964e925d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Get list of file Names\n",
        "\n",
        "%cd /content/drive/My Drive/Stories for GPT2\n",
        "\n",
        "import glob\n",
        "filenames = glob.glob(\"*.txt\")\n",
        "print(filenames)\n",
        "\n",
        "with open('corpus.txt', 'w') as outfile:\n",
        "    for fname in filenames:\n",
        "        with open(fname, encoding=\"Latin-1\") as infile:\n",
        "            outfile.write(infile.read())\n",
        "    outfile.close()\n",
        "\n",
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Stories for GPT2\n",
            "['internet_archive_scifi_v3.txt', 'Heretic-The-Life-of-a-Witch-Hunter.txt', 'The-24-Elders-The-Last-World.txt', 'Heavenly-Chat.txt', 'Escape-from-Samsara.txt', \"Alice's_Adventures_in_Wonderland_by_Lewis_Carroll.txt\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maQCBTKyRjeh",
        "outputId": "f6f1874f-e53f-4e28-e22f-f824f4965bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import shutil \n",
        " \n",
        "shutil.move('/content/drive/My Drive/Stories for GPT2/corpus.txt', '/content/gpt-2/src/corpus')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gpt-2/src/corpus/corpus.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trxVi6YQ3Y7e"
      },
      "source": [
        "Download Libraries and CUDA to prepare the environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_beptYv4Wsp"
      },
      "source": [
        "Now install Cuda v9.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHJzcTyTFfVn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O4Nqyoc4Vpz",
        "outputId": "02d33e14-c7cc-4e40-8ef4-afa0eb8b86a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local installers/cuda-repo-ubuntu1604-9-0-local 9.0.176-1 amd64-deb\n",
        "!dpkg -1 cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-*/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-0\n",
        " \n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-28 22:08:34--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.0.24\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.0.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2020-10-28 22:08:35 ERROR 404: Not Found.\n",
            "\n",
            "--2020-10-28 22:08:35--  http://installers/cuda-repo-ubuntu1604-9-0-local\n",
            "Resolving installers (installers)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘installers’\n",
            "--2020-10-28 22:08:35--  http://9.0.176-1/\n",
            "Resolving 9.0.176-1 (9.0.176-1)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘9.0.176-1’\n",
            "--2020-10-28 22:08:35--  http://amd64-deb/\n",
            "Resolving amd64-deb (amd64-deb)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘amd64-deb’\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m unknown option -1\n",
            "\n",
            "Type dpkg --help for help about installing and deinstalling packages [*];\n",
            "Use 'apt' or 'aptitude' for user-friendly package management;\n",
            "Type dpkg -Dhelp for a list of dpkg debug flag values;\n",
            "Type dpkg --force-help for a list of forcing options;\n",
            "Type dpkg-deb --help for help about manipulating *.deb files;\n",
            "\n",
            "Options marked [*] produce a lot of output - pipe it through 'less' or 'more' !\n",
            "gpg: can't open '/var/cuda-repo-*/7fa2af80.pub': No such file or directory\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [39.3 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [370 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,685 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [57.0 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,353 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [863 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.9 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,165 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.4 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,748 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [213 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,115 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [239 kB]\n",
            "Fetched 11.2 MB in 2s (4,830 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package cuda-9-0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3d9WTCi5-dA"
      },
      "source": [
        "Restart Runtime and move back to GPT2 folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DXHl1E6Epz",
        "outputId": "ea274cfd-d5a5-425a-f2b3-1943efc681d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-XolRzl6LQJ"
      },
      "source": [
        "Let's train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw7BDjEX6K1v",
        "outputId": "518bc0d8-15ac-4c30-b660-63b510648c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset src/corpus.txt --model_name '345M'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-10-28 12:27:44.451725: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-10-28 12:27:44.456225: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-28 12:27:44.456458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3013480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 12:27:44.456489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-28 12:27:44.460008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-28 12:27:44.643484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:44.643984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3013d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 12:27:44.644012: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-10-28 12:27:44.644972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:44.645320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-28 12:27:44.665128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-28 12:27:44.871329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-10-28 12:27:44.956949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-10-28 12:27:44.987172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-10-28 12:27:45.216022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-10-28 12:27:45.357179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-10-28 12:27:45.859479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-28 12:27:45.859701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:45.860200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:45.860553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-10-28 12:27:45.860646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-28 12:27:45.861761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-28 12:27:45.861790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-10-28 12:27:45.861800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-10-28 12:27:45.861915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:45.862305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 12:27:45.862671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-10-28 12:28:25.140115: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 321644800 exceeds 10% of system memory.\n",
            "2020-10-28 12:28:25.287855: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 321644800 exceeds 10% of system memory.\n",
            "2020-10-28 12:28:31.017271: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 321644800 exceeds 10% of system memory.\n",
            "2020-10-28 12:28:31.076755: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 321644800 exceeds 10% of system memory.\n",
            "2020-10-28 12:28:33.698767: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 321644800 exceeds 10% of system memory.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7GEG_Ud6jEb"
      },
      "source": [
        "The model will load the latest chechpoint and train from there (it seems that loading previously trained chechpoints and adding to it can lead you to run into memory problems with the 345M in colab). You can also specify the number of batches and learning rate. The number of batches real overall benefit is the speed of training, default batch size is 1, increasing the batch size can lead you into memory problems, so be careful how much you increase it especially when you are running on one GPU.\n",
        "\n",
        "While increasing the learning rate can increase the speed of training it could lead the model to get stuck at a local mininum (gradient) or even to overshoot so I recommended keeping the learning rate as is or decreasing it if the loss stops decreasing. The default learning rate is 0.00001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz3woR_F8SIl",
        "outputId": "d1196d1a-e17a-406e-83ec-469e275a5ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset src/corpus/corpus.txt --model_name '345M' --batch_size 2 --learning_rate 0.00001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:88: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:91: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-10-28 22:10:34.379152: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-10-28 22:10:34.383782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-28 22:10:34.384017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f3100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 22:10:34.384054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-28 22:10:34.387668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-28 22:10:34.581107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:34.581811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f32c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-28 22:10:34.581841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-28 22:10:34.582506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:34.583055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-28 22:10:34.595695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-28 22:10:34.804630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-10-28 22:10:34.895311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-10-28 22:10:34.913203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-10-28 22:10:35.148861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-10-28 22:10:35.296848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-10-28 22:10:35.795123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-28 22:10:35.795337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:35.796146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:35.796716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-10-28 22:10:35.796887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-28 22:10:35.798312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-28 22:10:35.798347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-10-28 22:10:35.798362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-10-28 22:10:35.798501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:35.799128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-28 22:10:35.799703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From ./train.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From ./train.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:121: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:89: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:144: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:147: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:152: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From ./train.py:156: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "Loading dataset...\n",
            "  0% 0/1 [00:00<?, ?it/s]^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YBlkrC88xk6"
      },
      "source": [
        "The model will save a checkpoint every 1000 steps. You can keep running it for minutes, hours or days, it all depends on you, just make sure you don't overfit the model if you have a small text. To stop the model simply \"stop\" it, it will have the last trained step (so if you stopped at step 1028, you will have two checkpoints 1000 and 1028. \n",
        "\n",
        "Note: When stopping the model while training in colab it might seem unresponsive and keep training, to avoid that, whiel it trains, clear the output and then stop it, this will save you a few clicks. \n",
        "\n",
        "Now that the model is trained, let's save the checkpoints in our Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG0krZPm8ojI"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/ /content/drive/My\\ Drive/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HJ3AK0e-Ibl"
      },
      "source": [
        "Copy the newly saved checkpoints into the model's directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4kt9I9s-PRV"
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/ /content/gpt-2/models/345M/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isMLHj_9-eQH"
      },
      "source": [
        "Generating Conditional Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF83k8PTTYEG"
      },
      "source": [
        "import os\n",
        "import shutil \n",
        " \n",
        "shutil.move('/content/gpt-2/condition_model.py', '/content/gpt-2/src')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O70tvy_W-hoT",
        "outputId": "14019a77-f80d-4c68-a0ba-50381e4005b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os \n",
        "%cd src\n",
        "from condition_model import conditional_model\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2/src\n",
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZcTgj8--xO3"
      },
      "source": [
        "Run the below code to find out what the method's arguments are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZOJkeT2-2jv"
      },
      "source": [
        "conditional_model??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeo2vYJA_Bek"
      },
      "source": [
        "Setting the seed helps you get reproducible results. The argument sentences take a string or a list of strings and return a dictionary with your input as key and the output sample as value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVbBgDer_Xmu",
        "outputId": "127e834f-91b9-40f2-9fef-75edfd47143e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "conditional_model(seed=None, nsamples=3, length=500, sentence='The lion and the Goat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "He will kill thy son\n",
            "\n",
            "By the power of the Great Spirit;\n",
            "\n",
            "That thou mayest find her in the earth. Psalm 30:10\n",
            "\n",
            "A lion that's a little over a hundred.\n",
            "\n",
            "A goat a little over one hundred.\n",
            "\n",
            "The lion and the Goat\n",
            "\n",
            "He will slay thy son;\n",
            "\n",
            "That thou mayest find her in the earth. Psalm 31:9\n",
            "\n",
            "There are various ways you can interpret how it could apply to the Holy Land (e.g. a lion has \"the power\" or the goat has the \"power\" but the only way in which one is capable of killing or hurting a lion in one's image). Here are some examples of things which might be interpreted as meaning that a lion is a good character which can be used in ways that a goat can't (e.g. a lion will help kill or hurt a goat):\n",
            "\n",
            "Lion or Goat : a man can be found who is good in his character and will kill the man while the guy in the image of a lion does the same thing.\n",
            "\n",
            "\n",
            "I would also interpret the meaning as the lions (with the word lion in between the lion) and goat have killed the innocent woman, but will not harm the innocent man, etc. This can be the one \"good\" character that a man can be and still be good in his own image.\n",
            "\n",
            "Dog, Tiger, or any Other Animal : a man can be found who uses a dog to attack his enemies, the dog will kill the enemy while the guy in the image of a lion will do the same thing.\n",
            "\n",
            "Lion or Goat : a man can be found who will kill the man while the guy in the image of a lion will do the same thing.\n",
            "\n",
            "I would be very wary about the interpretation here, it's possible that it could be the goats that have been created the lion as a hero but then killed the innocent man, etc, because they still do kill people, etc. It's also possible it could be that the image was created as part of a \"machismo\" or a \"genie\" who used to be able to kill or kill people (or just be killed) and the genie died in the fight and was replaced by someone who could be good in his own image, etc. The fact that the lion's name is also spelled as \"Lion\" suggests, though\n",
            "======================================== SAMPLE 2 ========================================\n",
            " is also one of my favorite stories. One evening in the 1930s I sat in my garden listening to old folk songs about an old woman lost in the forest. There was a story about her wandering alone in the midst of the misty fields, the lions approaching her with eager steps and she cried a sweet song in order to wake them up. In another, a lion came upon her and the lioness came up to him and said, \"You will never see me again.\" So I could do no more to save the tree. \"The Lion and Goliath\" is about the story of an old man found by oxen with two lionesses, one in disguise, but who had come to the village from Kerelo where he lived and had grown up and she was his wife who, when he was young, had been lost in the forest and was finally found her husband by oxen. After the lion got on the ox and tore its head off, the poor old widow said, \"I'll get my own, you see.\" A second lioness jumped over the edge and went back to her husband to seek them the day he died. The third lioness was the wife of the old lion. Two days later she saw her husband, was delighted at this good fortune, went to search for him and came back to the garden and saw her husband staring at her, and with a laugh said, \"Well, I suppose I'm going to look up my own head.\" Then it was said that the two lions in disguise came to her and took her away for safe keeping in a corner of a cave. \"The Lion and Goliath\" was one of those songs that really impressed my mother for so many years, and is what gave her the conviction that the only way to put up with old songs is to write and teach them. I'm pleased to report the Lion King has made it back to print with much fanfare. But I was always hoping.<|endoftext|>In July 2013 we ran a post asking people why they preferred Apple's iTunes and why, if iTunes 6 makes it into Macs and PCs, there are no plans to upgrade. We got hundreds of comments and I was shocked at the responses so I decided to look deeper.\n",
            "\n",
            "The main reason why most people prefer iTunes is because they need to use multiple iTunes installations at all times. This means that, if it makes sense to upgrade to iTunes 6 while you're running an older or unusable version\n",
            "======================================== SAMPLE 3 ========================================\n",
            ": A Study of the Relationship between the Gender Bias of Social Psychology and Personality Traits for the Managed Carer\" was published on March 14, 2016 by MIT Press.<|endoftext|>\"As I read the articles, it's difficult to believe that what has happened may not have been accidental, or that a lot of people will do something terrible as soon as somebody does something like this.\" -Aidan Gillen\n",
            "\n",
            "Dear Readers,\n",
            "\n",
            "With today's news that a teenage boy assaulted a girl in his home, most of you may have already read my previous post, How Teenagers are Affected by the World's Bad Teenagers. However there was another aspect of this news that I wanted to address today: We all have friends that have been sexually assaulted, either as a children or teenagers. Some are just innocent, and not even trying to make a mistake.\n",
            "\n",
            "Unfortunately, being the ignorant types, I think that the media would rather make these children scapegoats rather than the real issue, and by that I don't even mean sexual assault in the sense of the boy who went to that girl.\n",
            "\n",
            "What we are left with is victims who don't know anyone who was raped as a child, nor are they aware that they are potentially victims of sexual assault. For them to be made scapegoats in this way, is really sad and upsetting in its own right. What we need to see is real victims of crime and not victims of sexual assault who are being made innocent until proven guilty.\n",
            "\n",
            "The way I see it, the victims on the receiving end of these messages or the people who have had their lives put on hold through this event are not really victims in the sense of the man who was involved in the crime, and neither could they make up the story for the good of the girl, nor for either of the parties involved. They were not even aware that the girl in question had been assaulted. Not even by anyone associated with her or the situation.\n",
            "\n",
            "So I ask you all, please look past the victims as to the real issues, to the victims as to the way the public is being treated and we need to stop the cycle of the young victims and young boys being singled out as the victims of violent sex crimes and sexual violence as a whole.\n",
            "\n",
            "In fact, as people like you will know, not having any type of real understanding of young boys has never been a problem at all. It has come about organically and\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZrNVECbSAk",
        "outputId": "e14f9466-efbb-4247-95fe-5665d847d160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "conditional_model(seed=None, nsamples=3, length=10, sentences='The lion and the Goat,\" by Sir Walter Scott')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The lion and the Goat,\" by Sir Walter Scott': 'The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James, trans.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLEqjUxNfe4L",
        "outputId": "93cde00b-79c2-41ca-f617-e68d8704ddfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "conditional_model(seed=None, nsamples=3, length=10, sentences='The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James': 'The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James, (New York: Knopf, 1992'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TbuZYzak_Q-",
        "outputId": "b19c0247-ebeb-4adf-da2b-65eac2fbe942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "conditional_model(seed=None, nsamples=3, length=20, sentences='The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James': 'The lion and the Goat,\" by Sir Walter Scott, translated by Robert D. James\\n\\n\\n\"Beneath a tree,\" by Thomas More\\n\\n\\n\"Fortunate are the poor'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2rNBGVdlXH1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}